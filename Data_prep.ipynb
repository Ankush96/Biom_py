{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from skimage.util import img_as_float, img_as_ubyte\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath(\"../Data/test-ssrbc2015/segmentation\")\n",
    "\n",
    "def get_paths(directory):\n",
    "    \"\"\"Gets the filenames of all sclera images in the given directory along with their \n",
    "        ground truth images\n",
    "        Args:\n",
    "            directory: The path to the root folder\n",
    "        Output:\n",
    "            images: List of paths to files containing images\n",
    "            ground: List of paths to files containing corresponding ground truth images\n",
    "    \"\"\"\n",
    "    imgs = glob.glob(DATA_DIR+\"/[0-9]*/E*.jpg\")\n",
    "    imgs.sort()\n",
    "    gt = glob.glob(DATA_DIR+\"/[0-9]*/M*.jpg\")\n",
    "    gt.sort()\n",
    "    \n",
    "    # The following lines of code remove those examples whose image and ground truth \n",
    "    # sizes don't match\n",
    "    images = []\n",
    "    ground = []\n",
    "    for i in range(len(imgs)):\n",
    "        img = io.imread(imgs[i])\n",
    "        g = io.imread(gt[i])\n",
    "        if g.shape[0] == img.shape[0] and g.shape[1] == img.shape[1]:\n",
    "            images.append(imgs[i])\n",
    "            ground.append(gt[i])\n",
    "\n",
    "    return images, ground\n",
    "\n",
    "data, ground_truth = get_paths(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyper Params\n",
    "TRAIN_PATCHES = 1200\n",
    "VALIDATION_PATCHES = TRAIN_PATCHES/3\n",
    "TEST_PATCHES = TRAIN_PATCHES/3\n",
    "PATCHES_PER_IMAGE = 100\n",
    "POSITIVE_PROPORTION = 0.5               # Proportion of patches having positive class\n",
    "NUM_IMAGES = (TRAIN_PATCHES+VALIDATION_PATCHES+TEST_PATCHES)/PATCHES_PER_IMAGE\n",
    "PATCH_DIM = 31                          # Dimension of window used as a sample\n",
    "\n",
    "current_img_index = -1                  # Index of the current image in 'train'\n",
    "current_img = io.imread(data[0])\n",
    "current_gt = img_as_float(io.imread(ground_truth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_next_img(data, gt_data):\n",
    "    \"\"\"When we have extracted 'PATCHES_PER_IMAGE' number of patches from our \n",
    "       current image we call this function to change the current image\n",
    "       Args:\n",
    "           data: The list of paths to the sclera images\n",
    "           gt_data: List of paths to the corresponding ground truth images\n",
    "       \n",
    "    \"\"\"\n",
    "    global current_img_index, current_img, current_gt\n",
    "    if current_img_index < NUM_IMAGES-1 and current_img_index < len(data) - 1:\n",
    "        current_img_index +=1\n",
    "        print \"Working on image %d\"%(current_img_index + 1)\n",
    "        current_img = io.imread(data[current_img_index])                    \n",
    "        current_gt = img_as_float(io.imread(gt_data[current_img_index])) \n",
    "        # Some ground truth images are loaded as 3 channel images, which we convert\n",
    "        if (current_gt.shape) > 2:\n",
    "            current_gt = color.rgb2gray(current_gt)\n",
    "        return True\n",
    "    else:\n",
    "        print 'End of data extraction'\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrame\n",
      "Dataframe ready\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "print \"Creating DataFrame\"\n",
    "df = pd.DataFrame(index = np.arange(NUM_IMAGES*PATCHES_PER_IMAGE), columns = np.arange(PATCH_DIM**2*3+1))\n",
    "print \"Dataframe ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_img_data(data, gt_data):\n",
    "    \"\"\"Extracts PATCHES_PER_IMAGE number of patches from each image\n",
    "        \n",
    "       It maintains a count of positive and negative patches and maintains\n",
    "       the ratio POSITIVE_PROPORTION = pos/(pos+neg)\n",
    "       Args:\n",
    "           data: The list of paths to the sclera images\n",
    "           gt_data: List of paths to the corresponding ground truth images \n",
    "    \n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    global df\n",
    "    while pos_count +neg_count < PATCHES_PER_IMAGE: \n",
    "        # Choose a random point\n",
    "        i = np.random.randint(PATCH_DIM/2,current_img.shape[0]-PATCH_DIM/2-1)\n",
    "        j = np.random.randint(PATCH_DIM/2,current_img.shape[1]-PATCH_DIM/2-1)\n",
    "        \n",
    "        h = (PATCH_DIM - 1)/2\n",
    "        ind = current_img_index*PATCHES_PER_IMAGE+pos_count+neg_count\n",
    "        # If a positive sample is found and positive count hasn't reached its limit\n",
    "        if int(current_gt[i,j])==1 and pos_count < POSITIVE_PROPORTION*PATCHES_PER_IMAGE:\n",
    "            df.loc[ind][0:-1] = np.reshape(current_img[i-h:i+h+1,j-h:j+h+1], -1)\n",
    "            df.loc[ind][PATCH_DIM**2*3] = int(current_gt[i,j])\n",
    "            pos_count += 1\n",
    "        # If a negative sample is found and negative count hasn't reached its limit\n",
    "        elif int(current_gt[i,j])==0 and neg_count < (1-POSITIVE_PROPORTION)*PATCHES_PER_IMAGE:\n",
    "            df.loc[ind][0:-1] = np.reshape(current_img[i-h:i+h+1,j-h:j+h+1], -1)\n",
    "            df.loc[ind][PATCH_DIM**2*3] = int(current_gt[i,j])\n",
    "            neg_count += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image 1\n",
      "Time taken for this image = 0.078147 secs\n",
      "Working on image 2\n",
      "Time taken for this image = 0.067997 secs\n",
      "Working on image 3\n",
      "Time taken for this image = 0.066270 secs\n",
      "Working on image 4\n",
      "Time taken for this image = 0.077434 secs\n",
      "Working on image 5\n",
      "Time taken for this image = 0.066496 secs\n",
      "Working on image 6\n",
      "Time taken for this image = 0.066228 secs\n",
      "Working on image 7\n",
      "Time taken for this image = 0.080059 secs\n",
      "Working on image 8\n",
      "Time taken for this image = 0.066081 secs\n",
      "Working on image 9\n",
      "Time taken for this image = 0.065517 secs\n",
      "Working on image 10\n",
      "Time taken for this image = 0.075266 secs\n",
      "Working on image 11\n",
      "Time taken for this image = 0.065859 secs\n",
      "Working on image 12\n",
      "Time taken for this image = 0.070290 secs\n",
      "Working on image 13\n",
      "Time taken for this image = 0.066599 secs\n",
      "Working on image 14\n",
      "Time taken for this image = 0.068078 secs\n",
      "Working on image 15\n",
      "Time taken for this image = 0.066127 secs\n",
      "Working on image 16\n",
      "Time taken for this image = 0.066430 secs\n",
      "Working on image 17\n",
      "Time taken for this image = 0.066441 secs\n",
      "Working on image 18\n",
      "Time taken for this image = 0.066675 secs\n",
      "Working on image 19\n",
      "Time taken for this image = 0.066765 secs\n",
      "Working on image 20\n",
      "Time taken for this image = 0.065626 secs\n",
      "End of data extraction\n"
     ]
    }
   ],
   "source": [
    "while load_next_img(data, ground_truth):\n",
    "    start = time.time()\n",
    "    save_img_data(data, ground_truth)\n",
    "    print \"Time taken for this image = %f secs\" %( (time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df[:TRAIN_PATCHES]\n",
    "valid_df = df[TRAIN_PATCHES:TRAIN_PATCHES+VALIDATION_PATCHES]\n",
    "test_df = df[TRAIN_PATCHES+VALIDATION_PATCHES:TRAIN_PATCHES+VALIDATION_PATCHES+TEST_PATCHES]\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Normalising\n"
     ]
    }
   ],
   "source": [
    "print \"Mean Normalising\"\n",
    "last = len(df.columns) -1\n",
    "mean_img = np.mean(train_df)[:-1]\n",
    "\n",
    "train_labels = train_df[last]\n",
    "valid_labels = valid_df[last]\n",
    "test_labels = test_df[last]\n",
    "\n",
    "mean_normalised_train_df = train_df - np.mean(train_df)\n",
    "mean_normalised_train_df[last] = train_labels\n",
    "\n",
    "mean_normalised_valid_df = valid_df - np.mean(train_df)\n",
    "mean_normalised_valid_df[last] = valid_labels\n",
    "\n",
    "mean_normalised_test_df = test_df - np.mean(train_df)\n",
    "mean_normalised_test_df[last] = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly shuffling the datasets\n"
     ]
    }
   ],
   "source": [
    "print \"Randomly shuffling the datasets\"\n",
    "mean_normalised_train_df = mean_normalised_train_df.iloc[np.random.permutation(len(train_df))]\n",
    "mean_normalised_train_df = mean_normalised_train_df.reset_index(drop=True)\n",
    "mean_normalised_test_df = mean_normalised_test_df.iloc[np.random.permutation(len(test_df))]\n",
    "mean_normalised_test_df = mean_normalised_test_df.reset_index(drop=True)\n",
    "mean_normalised_valid_df = mean_normalised_valid_df.iloc[np.random.permutation(len(valid_df))]\n",
    "mean_normalised_valid_df = mean_normalised_valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to pickle\n"
     ]
    }
   ],
   "source": [
    "print \"Writing to pickle\"\n",
    "mean_img.to_pickle('../Data/test-ssrbc2015/segmentation/mean_img.pkl')\n",
    "mean_normalised_train_df.to_pickle('../Data/test-ssrbc2015/segmentation/mn_train.pkl')\n",
    "mean_normalised_valid_df.to_pickle('../Data/test-ssrbc2015/segmentation/mn_validation.pkl')\n",
    "mean_normalised_test_df.to_pickle('../Data/test-ssrbc2015/segmentation/mn_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken = 0.112412 mins\n"
     ]
    }
   ],
   "source": [
    "print \"Total time taken = %f mins\" %( (time.time()-begin)/60.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
